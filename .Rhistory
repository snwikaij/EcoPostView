df$b <- paste(df$p, "and", df$t)
unique(df$b)
coi1 <- ggplot(df, aes(1:nrow(df), y=x, col=b))+
geom_point(size=1)+xlab("Studies")+ylab("Effect-size")+
scale_color_manual(values = c( "tomato3","grey70","grey20", "dodgerblue3"))+
geom_linerange(data=df, aes(ymin=y, ymax=z), lwd=0.2)+
coord_flip()+
geom_hline(yintercept = 0.05)+
geom_hline(yintercept = 0, col="tomato3", lty=2)+
labs(col="")+
guides(col=guide_legend(ncol=1))+
theme_classic()+
theme(legend.position = "bottom",
axis.text.x = element_text(size=12),
axis.title.x =  element_text(size=12),
axis.text.y = element_text(size=12),
axis.title.y =  element_text(size=12),
#legend.text = element_text(margin = margin(b = .1), size=8),
legend.key.size = unit(5, "mm"),
legend.title = element_text(face=2),
legend.spacing.y = unit(0.1, "mm"))
coi1
df <- matrix(ncol=4, nrow=10)
set.seed(20)
for(f in 1:nrow(df)){
y      <- rnorm(30, 0.05, 0.25)
se     <- (sqrt(sum((y-mean(y))^2)/length(y)))/sqrt(length(y))
df[f,] <- c(mean(y), mean(y)-se*1.96, mean(y)+se*1.96, se)
}
df   <- setNames(as.data.frame(df), c("x", "y", "z", "s"))
df$p <- ifelse(df$y < 0.05 & df$z < 0.05, "Does not cover unknown true effect-size",
ifelse(df$y > 0.05 & df$z > 0.05, "Does not cover unknown true effect-size", "Covers unknown true effect-size"))
df$t <- ifelse(df$y > 0, "p-value < .05 ('significant')", "p-value > .05 ('non-significant')")
df$b <- paste(df$p, "and", df$t)
unique(df$b)
coi1 <- ggplot(df, aes(1:nrow(df), y=x, col=b))+
geom_point(size=1)+xlab("Studies")+ylab("Effect-size")+
scale_color_manual(values = c( "tomato3","grey70","grey20", "dodgerblue3"))+
geom_linerange(data=df, aes(ymin=y, ymax=z), lwd=0.2)+
coord_flip()+
geom_hline(yintercept = 0.05)+
geom_hline(yintercept = 0, col="tomato3", lty=2)+
labs(col="")+
guides(col=guide_legend(ncol=1))+
theme_classic()+
theme(legend.position = "bottom",
axis.text.x = element_text(size=12),
axis.title.x =  element_text(size=12),
axis.text.y = element_text(size=12),
axis.title.y =  element_text(size=12),
#legend.text = element_text(margin = margin(b = .1), size=8),
legend.key.size = unit(5, "mm"),
legend.title = element_text(face=2),
legend.spacing.y = unit(0.1, "mm"))
coi1
bias_example <- function(bstart=2, bend=0.05, length.out=5, nsim=1000, n=100, seed=666, fixed=T){
if(fixed == T)set.seed(seed)
beta  <- rev(seq(bend, bstart, length.out=length.out))
beta1 <- rep(beta, each=n)
beta2 <- t(array(beta, dim=c(length.out, n)))
fin_df <- array(NA, dim=c(nsim, length.out))
for(i in 1:nsim){
print(i)
list  <- lapply(rep(0,length.out), function(x) rnorm(n, x))
df    <- do.call(cbind, list)
df    <- as.data.frame(apply(df,2,as.numeric))
df    <- data.frame(y=rowSums(beta2*df)+rnorm(n, 0, 1),df)
fin_df[i,] <- rev(sapply(2:c(length.out+1), function(j) coef(lm(y~., data=df[c(1:j)]))[2]))}
fin_df     <- data.frame(par=beta[1], fin_df)
return(fin_df)}
test <- bias_example(length.out = 10, nsim = 3000)
par(mfrow=c(1,2))
hist(test[,1]-test[,2], breaks = 15, main="All 15 `true` predictors of y\n included in the model",
xlab="Error")
hist(test[,1]-test[,ncol(test)], main = "Only first `true` predictor of y\n included in the model",
xlab="Error")
1/sqrt(100-2)
sd((test[,1]-test[,2]))
sd((test[,1]-test[,ncol(test)]))
res <- ifelse(unique(test[,1])<test[,2]-1.96*(1/sqrt(100-2)), "not cover",
ifelse(unique(test[,1])<test[,2]+1.96*(1/sqrt(100-2)), "cover", "not cover"))
table(res)/sum(table(res))
res2 <- ifelse(unique(test[,1])<test[,ncol(test)]-1.96*(1/sqrt(100-2)), "not cover",
ifelse(unique(test[,1])<test[,ncol(test)]+1.96*(1/sqrt(100-2)), "cover", "not cover"))
table(res2)/sum(table(res2))
n_rep <- 200
n_sim <- 1000
minx  <- -0.5
maxx  <- .5
sim_list  <- vector("list", n_sim)
for(j in 1:n_sim){
print(j)
rep_mat <- array(NA, dim=c(n_rep, 2))
for(i in 3:n_rep){
x           <- seq(minx, maxx, length.out=i)
y           <- rnorm(i, 0+0.27*x, 0.37)
rep_mat[i,] <- c(i, summary(lm(y~x, data=data.frame(x, y)))$coefficients[2,4])
}
sim_list[[j]] <- rep_mat
}
n_rep <- 200
n_sim <- 1000
minx  <- -0.5
maxx  <- .5
sim_list  <- vector("list", n_sim)
for(j in 1:n_sim){
print(j)
rep_mat <- array(NA, dim=c(n_rep, 2))
for(i in 3:n_rep){
x           <- seq(minx, maxx, length.out=i)
y           <- rnorm(i, 0+0.25*x, 0.37)
rep_mat[i,] <- c(i, summary(lm(y~x, data=data.frame(x, y)))$coefficients[2,4])
}
sim_list[[j]] <- rep_mat
}
pwr_sim <- do.call(rbind.data.frame, sim_list)
pwr_sim <- aggregate(data=pwr_sim, V2~V1, mean)
plot(pwr_sim$V1, 1-pwr_sim$V2, type="l", xlab = "sample size", ylab="power")
sub_pwr <- pwr_sim$V2[1-pwr_sim$V2<0.8]
pwr_sim$V1[length(sub_pwr)]
dev.off()
plot(pwr_sim$V1, 1-pwr_sim$V2, type="l", xlab = "sample size", ylab="power")
abline(v=pwr_sim$V1[length(sub_pwr)])
plot(pwr_sim$V1, 1-pwr_sim$V2, type="l", xlab = "sample size (n)", ylab="power=(1-beta)")
sub_pwr <- pwr_sim$V2[1-pwr_sim$V2<0.8]
abline(v=pwr_sim$V1[length(sub_pwr)], col="red", lty=2)
abline(h=0.8, col="red", lty=2)
text(x=pwr_sim$V1[length(sub_pwr)]+5, y=0.8-0.05, text="A")
text(x=pwr_sim$V1[length(sub_pwr)]+5, y=0.8-0.05, label"A")
?text
text(x=pwr_sim$V1[length(sub_pwr)]+5, y=0.8-0.05, labels="A")
text(x=pwr_sim$V1[length(sub_pwr)]+10, y=0.8-0.05, labels="A")
text(x=pwr_sim$V1[length(sub_pwr)]+10, y=0.8-0.02, labels="A")
pwr_sim$V1[length(sub_pwr)]
pwr_sim$V1[length(sub_pwr)]
sub_pwr <- pwr_sim$V2[1-pwr_sim$V2<0.8]
abline(v=pwr_sim$V1[length(sub_pwr)], col="red", lty=2)
abline(h=0.8, col="red", lty=2)
text(x=pwr_sim$V1[length(sub_pwr)]+10, y=0.8-0.02, labels=paste("Needed sample size = " pwr_sim$V1[length(sub_pwr)]))
plot(pwr_sim$V1, 1-pwr_sim$V2, type="l", xlab = "sample size (n)", ylab="power=(1-beta)")
sub_pwr <- pwr_sim$V2[1-pwr_sim$V2<0.8]
abline(v=pwr_sim$V1[length(sub_pwr)], col="red", lty=2)
abline(h=0.8, col="red", lty=2)
text(x=pwr_sim$V1[length(sub_pwr)]+10, y=0.8-0.02, labels=paste("Needed sample size = " pwr_sim$V1[length(sub_pwr)]))
text(x=pwr_sim$V1[length(sub_pwr)]+10, y=0.8-0.02, labels=paste("Needed sample size = ", pwr_sim$V1[length(sub_pwr)]))
sub_pwr <- pwr_sim$V2[1-pwr_sim$V2<0.8]
abline(v=pwr_sim$V1[length(sub_pwr)], col="red", lty=2)
abline(h=0.8, col="red", lty=2)
text(x=pwr_sim$V1[length(sub_pwr)]+25, y=0.8-0.02, labels=paste("Needed sample size = ", pwr_sim$V1[length(sub_pwr)]))
plot(pwr_sim$V1, 1-pwr_sim$V2, type="l", xlab = "sample size (n)", ylab="power=(1-beta)")
sub_pwr <- pwr_sim$V2[1-pwr_sim$V2<0.8]
abline(v=pwr_sim$V1[length(sub_pwr)], col="red", lty=2)
abline(h=0.8, col="red", lty=2)
text(x=pwr_sim$V1[length(sub_pwr)]+35, y=0.8-0.02, labels=paste("Needed sample size = ", pwr_sim$V1[length(sub_pwr)]))
beta <- c(0.2, 0.5, 0, 0.1, 0, 0.01)
n <- 100
array(rnorm(n), length(beta))
array(rnorm(), , dim=c(n, length(beta)))
array(rnorm(n*length(beta)), dim=c(n, length(beta)))
xmat <- array(rnorm(n*length(beta)), dim=c(n, length(beta)))
beta*x
sweep(xmat, 2, beta, FUN = "*")
rowSums(sweep(xmat, 2, beta, FUN = "*"))
beta <- c(0.2, 0.5, 0, 0.1, 0, 0.01)
n <- 100
sigma <- 1
xmat <- array(rnorm(n*length(beta)), dim=c(n, length(beta)))
rowSums(sweep(xmat, 2, beta, FUN = "*"))+rnorm(n*length(beta), 0, sigma)
y <- rowSums(sweep(xmat, 2, beta, FUN = "*"))+rnorm(n*length(beta), 0, sigma)
lm(y~xmat)
cbind(y, xmat)
df <- cbind.data.frame(y, xmat)
lm(y~., data=df)
step(mod, direction = "backward")
df  <- cbind.data.frame(y, xmat)
mod <- lm(y~., data=df)
step(mod, direction = "backward")
df   <- cbind.data.frame(y, xmat)
mod0 <- lm(y~1, data=df)
mod1 <- lm(y~., data=df)
step(mod0,scope = list(lower = mod0, upper = mod1), direction = "both")
mod <- step(mod0, scope = list(lower = mod0, upper = mod1), direction = "both")
library(olsrr)
install.packages("olsrr")
library(olsrr)
xmat <- array(rnorm(n*length(beta)), dim=c(n, length(beta)))
y <- rowSums(sweep(xmat, 2, beta, FUN = "*"))+rnorm(n*length(beta), 0, sigma)
df   <- cbind.data.frame(y, xmat)
mod0 <- lm(y~1, data=df)
mod1 <- lm(y~., data=df)
step(mod, direction = "backward")
mod <- step(mod0, scope = list(lower = mod0, upper = mod1), direction = "both")
ols_step_both_p(model)
ols_step_both_p(mod1)
mod_fin2 <- ols_step_both_p(mod1)
mod_fin2
mod_fin2$metrics
mod_fin2$model
summary(mod_fin2$model)
coef(summary(mod_fin2$model))
coef(summary(mod_fin2$model))[,c(1,2)]
mod_fin <- ols_step_both_p(mod1)
coef(summary(mod_fin2$model))[,c(1,2)]
coef(mod_fin)
mod_fin <- ols_step_both_p(mod1)
coef(mod_fin)
coef(summary(mod_fin))
mod_fin <- ols_step_both_p(mod1)
coef(summary(mod_fin))
summary(mod_fin)
mod1 <- lm(y~., data=df)
mod_fin <- ols_step_both_p(mod1)
coef(summary(mod_fin))
summary(mod_fin)
selection_bias <- function(beta,  sigma, n){
xmat <- array(rnorm(n*length(beta)), dim=c(n, length(beta)))
y <- rowSums(sweep(xmat, 2, beta, FUN = "*"))+rnorm(n*length(beta), 0, sigma)
df   <- cbind.data.frame(y, xmat)
mod1 <- lm(y~., data=df)
mod_fin <- ols_step_both_p(mod1)
summary(mod_fin)
}
summary(mod_fin$model)
rownames(coef(summary(mod_fin$model)))
rownames(coef(summary(mod_fin$model)))[-1]
as.numeric(rownames(coef(summary(mod_fin$model)))[-1])
as.numeric(as.character(rownames(coef(summary(mod_fin$model)))[-1]))
rownames(coef(summary(mod_fin$model)))[-1])
rownames(coef(summary(mod_fin$model)))[-1]))
rownames(coef(summary(mod_fin$model))[-1])
coef(summary(mod_fin$model))
rownames(coef(summary(mod_fin$model)))
rownames(coef(summary(mod_fin$model)))[-1]
select <- rownames(coef(summary(mod_fin$model)))[-1]
as.numeric(select)
gsub("`", "", select)
as.numeric(gsub("`", "", select))
length(beta)
c(1:length(beta))
rep(NA, length(beta))
total <- rep(NA, length(beta))
total <- c(1:length(beta))
total
ifelse(total%in%1, 1, 0)
ifelse(total %in% select, 1, 0)
select
mod_fin <- ols_step_both_p(mod1)
select <- rownames(coef(summary(mod_fin$model)))[-1]
select <- as.numeric(gsub("`", "", select))
total <- c(1:length(beta))
ifelse(total %in% select, 1, 0)
coef(mod1)
coef(summary(mod1))
coef(summary(mod1))[,4]
coef(summary(mod1))[,4]<0.05
coef(summary(mod1))
rownames(coef(summary(mod1)))[coef(summary(mod1))[,4]<0.05]
select
rownames(coef(summary(mod1)))[coef(summary(mod1))[,4]<0.05]
as.numeric(gsub(rownames(coef(summary(mod1)))[coef(summary(mod1))[,4]<0.05]))
as.numeric(gsub(rownames(coef(summary(mod1)))[coef(summary(mod1))[,4]<0.05]))
rownames(coef(summary(mod1)))[coef(summary(mod1))[,4]<0.05])
rownames(coef(summary(mod1)))[coef(summary(mod1))[,4]<0.05]
gsub("`", "", rownames(coef(summary(mod1)))[coef(summary(mod1))[,4]<0.05])
as.numeric(gsub("`", "", rownames(coef(summary(mod1)))[coef(summary(mod1))[,4]<0.05]))
as.numeric(gsub("`", "", rownames(coef(summary(mod1)))[coef(summary(mod1))[,4]<0.05]))
sig <- as.numeric(gsub("`", "", rownames(coef(summary(mod1)))[coef(summary(mod1))[,4]<0.05]))
sig_select <- c(1:length(beta))
ifelse(total %in% select, 1, 0)
ifelse(total %in% sig, 1, 0)
selection_bias <- function(beta,  sigma, n){
xmat <- array(rnorm(n*length(beta)), dim=c(n, length(beta)))
y    <- rowSums(sweep(xmat, 2, beta, FUN = "*"))+rnorm(n*length(beta), 0, sigma)
df   <- cbind.data.frame(y, xmat)
mod1 <- lm(y~., data=df)
sig <- as.numeric(gsub("`", "", rownames(coef(summary(mod1)))[coef(summary(mod1))[,4]<0.05]))
mod_fin <- ols_step_both_p(mod1)
select <- rownames(coef(summary(mod_fin$model)))[-1]
select <- as.numeric(gsub("`", "", select))
total <- c(1:length(beta))
list(step=  ifelse(total %in% select, 1, 0), non=ifelse(total %in% sig, 1, 0))}
selection_bias()
selection_bias <- function(c(0.2, 0.5, 0, 0.1, 0, 0.01),  sigma=1, n=100){
selection_bias()
selection_bias <- function(beta=c(0.2, 0.5, 0, 0.1, 0, 0.01), sigma=1, n=100){
xmat <- array(rnorm(n*length(beta)), dim=c(n, length(beta)))
y    <- rowSums(sweep(xmat, 2, beta, FUN = "*"))+rnorm(n*length(beta), 0, sigma)
df   <- cbind.data.frame(y, xmat)
mod1 <- lm(y~., data=df)
sig <- as.numeric(gsub("`", "", rownames(coef(summary(mod1)))[coef(summary(mod1))[,4]<0.05]))
mod_fin <- ols_step_both_p(mod1)
select <- rownames(coef(summary(mod_fin$model)))[-1]
select <- as.numeric(gsub("`", "", select))
total <- c(1:length(beta))
list(step=  ifelse(total %in% select, 1, 0), non=ifelse(total %in% sig, 1, 0))}
selection_bias()
selection_bias <- function(beta=c(0.2, 0.5, 0, 0.1, 0, 0.01), sigma=1, n=100){
xmat <- array(rnorm(n*length(beta)), dim=c(n, length(beta)))
y    <- rowSums(sweep(xmat, 2, beta, FUN = "*"))+rnorm(n*length(beta), 0, sigma)
df   <- cbind.data.frame(y, xmat)
mod1 <- lm(y~., data=df)
sig <- as.numeric(gsub("`", "", rownames(coef(summary(mod1)))[coef(summary(mod1))[,4]<0.05]))
mod_fin <- ols_step_both_p(mod1)
select <- rownames(coef(summary(mod_fin$model)))[-1]
select <- as.numeric(gsub("`", "", select))
total <- c(1:length(beta))
list(step=  ifelse(total %in% select, 1, 0), non=ifelse(total %in% sig, 1, 0))}
selection_bias()
selection_bias()
selection_bias()
selection_bias()
selection_bias()
selection_bias()
selection_bias()
selection_bias()
selection_bias()
selection_bias()
selection_bias()
compare <- selection_bias()
compare$step
compare$non
b <- c(0.2, 0.5, 0, 0.1, 0, 0.01)
compare <- selection_bias(beta=b)
array(NA, dim(1000, length(beta)))
b <- c(0.2, 0.5, 0, 0.1, 0, 0.01)
array(NA, dim(1000, length(beta)))
array(NA, dim=c(1000, length(beta)))
stepwise_error <- array(NA, dim=c(1000, length(beta)))
compare             <- selection_bias(beta=b)
stepwise_errorp[i,] <- compare$step
non_error[i,]       <- compare$non
b <- c(0.2, 0.5, 0, 0.1, 0, 0.01)
stepwise_error <- array(NA, dim=c(1000, length(beta)))
non_error     <- array(NA, dim=c(1000, length(beta)))
b             <- c(0.2, 0.5, 0, 0.1, 0, 0.01)
stepwise_error<- array(NA, dim=c(1000, length(beta)))
non_error     <- array(NA, dim=c(1000, length(beta)))
b             <- c(0.2, 0.5, 0, 0.1, 0, 0.01)
stepwise_error<- array(NA, dim=c(1000, length(beta)))
non_error     <- array(NA, dim=c(1000, length(beta)))
for(i in 1:1000){
compare             <- selection_bias(beta=b)
stepwise_errorp[i,] <- compare$step
non_error[i,]       <- compare$non
}
b             <- c(0.2, 0.5, 0, 0.1, 0, 0.01)
stepwise_error<- array(NA, dim=c(1000, length(beta)))
non_error     <- array(NA, dim=c(1000, length(beta)))
for(i in 1:1000){
compare             <- selection_bias(beta=b)
stepwise_error[i,]  <- compare$step
non_error[i,]       <- compare$non
}
b             <- c(0.2, 0.5, 0, 0.1, 0, 0.01)
stepwise_error<- array(NA, dim=c(1000, length(beta)))
non_error     <- array(NA, dim=c(1000, length(beta)))
for(i in 1:1000){
print(i)
compare             <- selection_bias(beta=b)
stepwise_error[i,]  <- compare$step
non_error[i,]       <- compare$non
}
colSums(stepwise_error)
colSums(non_error)
colSums(stepwise_error)/1000
colSums(non_error)/100
colSums(non_error)/1000
(colSums(stepwise_error)/1000)/(colSums(non_error)/1000)
b             <- c(0.5, 0.4, 0.3, 0.2, 0.1 0.05, 0.01, 0)
stepwise_error<- array(NA, dim=c(1000, length(beta)))
non_error     <- array(NA, dim=c(1000, length(beta)))
for(i in 1:1000){
print(i)
compare             <- selection_bias(beta=b)
stepwise_error[i,]  <- compare$step
non_error[i,]       <- compare$non
}
(colSums(stepwise_error)/1000)/(colSums(non_error)/1000)
(colSums(non_error)/1000)
(colSums(stepwise_error)/1000)
barplot((colSums(non_error)/1000))
load("C:/Users/admin/OneDrive/Bureaublad/Epistemology/Crap/lalalalala.RData")
library(MASS)
b1 <- 0
b2 <- 0.2
b3 <- 0
b4 <- 0.2
b5 <- 0.3
b6 <- 0.1
b7 <- 0
b8 <- 0.35
b9 <- 0.6
b10 <- 0
bstart <- 5
bend <- 100
bstep <- 1
length.out <- 100
nmu <- 10
sigma <- 1
nsim <- 1000
n    <- 100
seed <- 666
sigma1 <- matrix(0, ncol = nmu, nrow = nmu)
diag(sigma1) <- sigma
sigma1[lower.tri(sigma1)] <- 0.3
sigma1[upper.tri(sigma1)] <- 0.3
simlist <- vector("list", nsim)
fullist <- vector("list", nsim)
for(i in 1:nsim){
print(i)
res <- mvrnorm(n, mu = rep(0, nmu), Sigma = sigma1)
y <- rnorm(nrow(res), b1*res[,1]+b2*res[,2]+b3*res[,3]+b4*res[,4]+b5*res[,5]+b6*res[,6]+b7*res[,7]+b8*res[,8]+b9*res[,9]+b10*res[,10], 1)
df <- as.data.frame(res)
df$y <- y
full <- lm(y ~ V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10, data = df)
fullist[[i]] <- rownames(coef(summary(full)))[coef(summary(full))[,4] < 0.05]
sumstep <- summary(step(full, direction = "both", trace = FALSE, test = "F"))
simlist[[i]] <- rownames(coef(sumstep))
}
set <- unlist(simlist)
set <- set[!set %in% "(Intercept)"]
set2 <- unlist(fullist)
set2 <- set2[!set2 %in% "(Intercept)"]
errtab <- rbind(c(b1, b2, b3, b4, b5, b6, b7, b8, b9, b10),
table(set) / nsim,
table(set2) / nsim)
ertab2 <- round(rbind(errtab,
(errtab[2,]/errtab[3,])),2)
rownames(ertab2) <- c("effect-size", "forward-backward", "none", "ratio")
ertab2
postdens       <- pdplot(mod_inv, title_size = 2, point_size = .8, line_width = .7, err_bar_lwd = .5,
xlab=c("Pooled parameter estimate [=regression coefficient]"),
ylab=c("Probability distribution"),
order_predictor = order_p, order_group = order_g)
library(readxl)
library(ggplot2)
library(parallel)
library(usethis)
library(mime)
library(devtools)
library(gridExtra)
library(grid)
#JAGS needs to be installed from https://sourceforge.net/projects/mcmc-jags/
library(R2jags)
#For further information check https://snwikaij.github.io/EcoPostView/EcoPostView.html
#One needs to install the package from GitHub
devtools::install_github("snwikaij/EcoPostView")
#Get wd, this will be the location where all figures will be stored.
wd <- getwd()
#Detect number of cores
numberofcores <- parallel::detectCores()
#Upload the data (literature) and priors
url         <- "https://raw.githubusercontent.com/snwikaij/Data/main/Unknown_Kaijser_et_al._2025_Supplementary_Information_2.xlsx"
destfile    <- tempfile(fileext = ".xlsx")
download.file(url, destfile, mode = "wb")
literature  <- read_xlsx(destfile, 1)
priors      <- read_xlsx(destfile, 3)
#Total number of articles
nrow(litres2 <- literature[!duplicated(literature$DOI),])
#Systematic and non-systematic
table(literature$sys[!duplicated(literature$DOI)])
#Total number of models
nrow(litres1 <- literature[literature$Parameter == "b0",])
#Log and logit-linear models
table(literature$Link[literature$Parameter == "b0"])
#Total log and logit-linear model parameters
table(literature$Link[literature$Parameter == "b1"])
#Create dataset for the model
mod_data <- data.frame(group=literature$Response,
predictor=literature$Fignames,
level=paste(literature$Parameter, literature$Type, literature$Link, literature$Response, sep = "_"),
estimate=literature$estimate,
stderr=literature$estimate_se,
linkfun=literature$Link)
#Full model
mod <- meta(estimate = mod_data$estimate,
stderr = mod_data$stderr,
parameter = do.call(rbind, strsplit(mod_data$level, "_"))[,1],
predictor = mod_data$predictor,
link_function = mod_data$linkfun,
grouping = mod_data$group,
prior_mu = as.data.frame(priors[c(2,4,6,8)]),
prior_mu_se = as.data.frame(priors[c(3,5,7,9)]),
prior_study_var = 5,
n_iter = 30000,
n_thin = 30,
n_chain= numberofcores)
##############
#Select order#
##############
order_p     <- c("Salinity-increase", "Oxygen-depletion", "Sediment-enrichment", "Warming", "Flow-cessation", "N-increase", "P-increase")
order_g     <- c("Bacteria", "Algae", "Macrophytes", "Invertebrates", "Fish")
####################################################
#Posterior residual bias check (figures S7,8 and 9)#
####################################################
residual_check <- rescheck(mod, order_predictor = order_p, order_group = order_g)
ggsave(residual_check$bias_se, filename=paste0(wd,"/Fig_S7.jpeg"), units = "mm", width = 200, height = 120, dpi = 300)
ggsave(residual_check$bias_se_group, filename=paste0(wd,"/Fig_S8.jpeg"), units = "mm", width = 200, height = 120, dpi = 300)
ggsave(residual_check$bias_se_predictor, filename=paste0(wd,"/Fig_S9.jpeg"), units = "mm", width = 200, height = 120, dpi = 300)
###########
#Inversion#
###########
#I am (as main author) the least happy with this. To bring this to a general audience the
#relation of flow and oxygen was inversed. Hence, the idea is that flow increase and oxygen
#increase are not stressors. Therefore they are inversed by multiplying with -1.
#The issue I have is that there exists no inverse of flow velocity (m/s) and oxygen (mg/l).
#For proper interpretation and prediction it does not work well.
mod_inv <- mod
mod_inv$Estimates$b1$estimate[mod_inv$Estimates$b1$predictor %in% c("Flow-cessation", "Oxygen-depletion")] <- -1*mod_inv$Estimates$b1$estimate[mod_inv$Estimates$b1$predictor %in% c("Flow-cessation", "Oxygen-depletion")]
?pwrr
?pwrrs
?pwrss.chisq.gofit
