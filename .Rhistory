post_df    <- as.data.frame(array(NA, dim=c(length(mod$present),2)))
post_df$V1 <- names(mod$present)[order(names(mod$present))]
for(j in 1:length(mod[[1]])){
present <- mod[["present"]][[j]]
absent  <- mod[["absent"]][[j]]
p1 <- (n_spec[j,2]/n_samp)
p0 <- ((n_samp-n_spec[j,2])/n_samp)
y1 <- as.numeric()
y0 <- as.numeric()
for(k in pred_names){
x     <- as.numeric(xd[k])
y1[k] <- dlnorm(x, present[1,which(colnames(present) == k)], present[2,which(colnames(present) == k)])
y0[k] <- dlnorm(x, absent[1,which(colnames(absent) == k)], absent[2,which(colnames(absent) == k)])
}
post_df[j,2] <- (prod(y1)*p1)/(prod(y1)*p1+prod(y0)*p0)}
post_df}
for(t in 1:length(spec_list$present)){
for(v in 2:(length(pred_names)+1)){
spec    <- spec_list$present[[t]]
spec_list$present[[t]][1,v] <- abmeta(spec_list$present[[t]][1,v],spec_list$present[[t]][2,v],
total[1,v], total[2,v])}}
spec_list$present[[t]][1,v]
for(t in 1:length(spec_list$present)){
for(v in 2:(length(pred_names)+1)){
spec    <- spec_list$present[[t]]
spec_list$present[[t]][1,v] <- abmeta(spec_list$present[[t]][1,v],spec_list$present[[t]][2,v],
total[1,v], total[2,v])[1]}}
abmeta(spec_list$present[[t]][1,v],spec_list$present[[t]][2,v],
total[1,v], total[2,v])[1]
spec    <- spec_list$present[[t]]
spec_list$present[[t]]
df     <- read.csv(url("https://raw.githubusercontent.com/snwikaij/Data/refs/heads/main/Hydrobiologia_Kaijser_et_al._2022.csv"), header = T)
df     <- df[!duplicated(paste(df$ID, df$Species)),]
df     <- df[c("Species", "ID", "EC", "NNO3", "pH", "Temp", "PPO4")]
df$NNO3<- df$NNO3/14*62
colnames(df)[4] <- "NO3"
df$PPO4<- df$PPO4/31*95
colnames(df)[7] <- "PO4"
df <- df[df$Species %in% names(table(df$Species))[table(df$Species)>10],]
df <- df[rowSums(df == 0, na.rm = TRUE) == 0, ]
total <- cbind.data.frame('all', rbind(colMeans(log(df[!duplicated(df$ID),][-c(1:2)]), na.rm = T), apply(log(df[!duplicated(df$ID),][-c(1:2)]), 2, function(x) sd(x, na.rm = T))))
colnames(total)[1] <- "Taxon"
#function(taxa, env, id, group=NULL, minimal=10)
n_spec     <- as.data.frame(table(df$Species))
pred_names <- colnames(df)[-c(1:2)]
spec_list        <- vector("list", 2)
names(spec_list) <- c("present", "absent")
for(i in unique(df$Species)){
present        <- df[df$Species == i,]
absent         <- df[!df$ID %in% present$ID,]
absent         <- absent[!duplicated(absent$ID),]
absent$Species <- i
est_par <- function(d,i){
g <- as.data.frame(apply(d[-c(1:2)], 2, function(x) c(mean(log(x), na.rm=T), sd(log(x), na.rm = T))))
cbind(Taxon=i, g)}
present <- est_par(present, i)
spec_list[["present"]][[i]] <- present
spec_list[["absent"]][[i]]  <- est_par(absent, i)}
spec_list[["present"]] <- Filter(function(df) !any(is.na(df)),  spec_list[["present"]])
spec_list[["absent"]]  <- spec_list[["absent"]][names(spec_list[["present"]])]
n_spec                 <- n_spec[n_spec$Var1 %in% names(spec_list$present),]
n_spec$Var1  <- factor(n_spec$Var1, levels = names(spec_list$present))
n_spec       <- n_spec[order(n_spec$Var1),]
df_subset    <- df[df$Species %in% n_spec$Var1,]
n_samp       <- length(unique(df$ID))
abmeta(spec_list$present[[t]][1,v],spec_list$present[[t]][2,v],
total[1,v], total[2,v])[1]
for(t in 1:length(spec_list$present)){
for(v in 2:(length(pred_names)+1)){
spec_list$present[[t]][1,v] <- abmeta(spec_list$present[[t]][1,v],spec_list$present[[t]][2,v],
total[1,v], total[2,v])[1]}}
predict <- function(mod, new){
post_df    <- as.data.frame(array(NA, dim=c(length(mod$present),2)))
post_df$V1 <- names(mod$present)[order(names(mod$present))]
for(j in 1:length(mod[[1]])){
present <- mod[["present"]][[j]]
absent  <- mod[["absent"]][[j]]
p1 <- (n_spec[j,2]/n_samp)
p0 <- ((n_samp-n_spec[j,2])/n_samp)
y1 <- as.numeric()
y0 <- as.numeric()
for(k in pred_names){
x     <- as.numeric(xd[k])
y1[k] <- dlnorm(x, present[1,which(colnames(present) == k)], present[2,which(colnames(present) == k)])
y0[k] <- dlnorm(x, absent[1,which(colnames(absent) == k)], absent[2,which(colnames(absent) == k)])
}
post_df[j,2] <- (prod(y1)*p1)/(prod(y1)*p1+prod(y0)*p0)}
post_df}
xd      <- data.frame(pH=7.6, EC=500, Temp=16, NO3=1, PO4=0.1)
pred_df <- predict(spec_list, xd)
ggplot(pred_df, aes(x=reorder(V1, -V2, mean), weight=V2, fill=V2))+ylab("Posterior probability P(Taxa|Data)")+
geom_bar(col="black")+theme_classic()+scale_fill_gradient(low="grey100", high = "grey0", limits=c(0,1))+labs(fill="P(Taxa|Data)")+
theme(axis.text.x = element_text(angle = 45, hjust = 1),
axis.title.x = element_blank())
predict <- function(mod, new){
post_df    <- as.data.frame(array(NA, dim=c(length(mod$present),2)))
post_df$V1 <- names(mod$present)[order(names(mod$present))]
for(j in 1:length(mod[[1]])){
present <- mod[["present"]][[j]]
absent  <- mod[["absent"]][[j]]
p1 <- (n_spec[j,2]/n_samp)
p0 <- ((n_samp-n_spec[j,2])/n_samp)
y1 <- as.numeric()
y0 <- as.numeric()
for(k in pred_names){
x     <- as.numeric(xd[k])
y1[k] <- dlnorm(x, present[1,which(colnames(present) == k)], present[2,which(colnames(present) == k)])
y0[k] <- dlnorm(x, absent[1,which(colnames(absent) == k)], absent[2,which(colnames(absent) == k)])
}
post_df[j,2] <- (prod(y1)*p1)/(prod(y1)*p1+prod(y0)*p0)}
post_df}
df$EC
quantile(df$EC, c(.025, .975))
quantile(df$EC, c(.025, .975), na.rm = T)
qa <- quantile(df$EC, c(.025, .975), na.rm = T)
seq(qa[1], qa[2], 1)
predict(spec_list, data.frame(EC=seq(qa[1], qa[2], 1)))
data.frame(EC=seq(qa[1], qa[2], 1)
predict(spec_list, ))
data.frame(EC=seq(qa[1], qa[2], 1))
yhat <- data.frame(EC=seq(qa[1], qa[2], 1))
yhat
predict(spec_list, yhat[i,]))
predict(spec_list, yhat[i,])
yhat[i,]
i
predict(spec_list)
for(i in 1:nrow(yhat)){}
predict(spec_list, yhat[i,])}
yhat <- data.frame(EC=seq(qa[1], qa[2], 1))
for(i in 1:nrow(yhat)){
predict(spec_list, yhat[i,])}
i
predict(spec_list, yhat[i,])
predlist <- list()
yhat <- data.frame(EC=seq(qa[1], qa[2],5))
predlist <- list()
for(i in 1:nrow(yhat)){
predlist[i] <- predict(spec_list, yhat[i,])}
warnings()
yhat <- data.frame(EC=seq(qa[1], qa[2],5))
predlist <- list()
for(i in 1:nrow(yhat)){
predlist[[i]] <- predict(spec_list, yhat[i,])}
do.call(rbind, predlist)
do.call(cbind, predlist)
what <- do.call(cbind, predlist)
View(what)
predict(spec_list, yhat[i,])
predict(spec_list, yhat[i,])[-1]
yhat <- data.frame(EC=seq(qa[1], qa[2],5))
predlist <- list()
for(i in 1:nrow(yhat)){
predlist[[i]] <- predict(spec_list, yhat[i,])[,-1]}
rbind(predlist)
do.call(rbind, predlist)
what <- do.call(rbind, predlist)
View(what)
yhat <- data.frame(EC=seq(qa[1], qa[2],20))
predlist <- list()
for(i in 1:nrow(yhat)){
predlist[[i]] <- predict(spec_list, yhat[i,])[,-1]}
what <- do.call(rbind, predlist)
what
View(what)
yhat <- data.frame(EC=seq(qa[1], qa[2],20),
NO3=total$NO3[1],
pH=total$pH[1],
Temp=total$Temp[1],
PO4=total$PO4)
predlist <- list()
for(i in 1:nrow(yhat)){
predlist[[i]] <- predict(spec_list, yhat[i,])[,-1]}
what <- do.call(rbind, predlist)
what
yhat[i,]
xd <- yhat
pred_df <- predict(spec_list, xd)
xd
yhat[i,]
xd <- yhat[i,]
pred_df <- predict(spec_list, xd)
ggplot(pred_df, aes(x=reorder(V1, -V2, mean), weight=V2, fill=V2))+ylab("Posterior probability P(Taxa|Data)")+
geom_bar(col="black")+theme_classic()+scale_fill_gradient(low="grey100", high = "grey0", limits=c(0,1))+labs(fill="P(Taxa|Data)")+
theme(axis.text.x = element_text(angle = 45, hjust = 1),
axis.title.x = element_blank())
df$EC
qa <- log(quantile(df$EC, c(.025, .975), na.rm = T))
yhat <- data.frame(EC=seq(qa[1], qa[2],20),
NO3=total$NO3[1],
pH=total$pH[1],
Temp=total$Temp[1],
PO4=total$PO4)
seq(qa[1], qa[2],20)
seq(qa[1], qa[2],20)
seq(qa[1], qa[2],20)
seq(qa[1], qa[2],20)
qa
seq(qa[1], qa[2], 20)
yhat <- data.frame(EC=seq(qa[1], qa[2], length.out=20),
NO3=total$NO3[1],
pH=total$pH[1],
Temp=total$Temp[1],
PO4=total$PO4)
predlist <- list()
for(i in 1:nrow(yhat)){
predlist[[i]] <- predict(spec_list, yhat[i,])[,-1]}
what <- do.call(rbind, predlist)
what
predict(spec_list)
predict(spec_list, yhat[i,])[-1]
what
what <- do.call(cbind, predlist)
View(what)
yhat
yhat[i,]
total$NO3[1]
qa <- quantile(df$EC, c(.025, .975), na.rm = T)
yhat <- data.frame(EC=seq(qa[1], qa[2], length.out=20),
NO3=exp(total$NO3[1]),
pH=exp(total$pH[1]),
Temp=exp(total$Temp[1]),
PO4=exp(total$PO4[1]))
predlist <- list()
for(i in 1:nrow(yhat)){
predlist[[i]] <- predict(spec_list, yhat[i,])[,-1]}
what <- do.call(cbind, predlist)
View(what)
View(what)
yhat[i,]
i=10
predict(spec_list, yhat[i,])
predict(spec_list, yhat[10,])
yhat <- data.frame(EC=seq(qa[1], qa[2], length.out=20),
NO3=2,
pH=7.8,
Temp=18,
PO4=0.15)
predlist <- list()
for(i in 1:nrow(yhat)){
predlist[[i]] <- predict(spec_list, yhat[i,])[,-1]}
what <- do.call(cbind, predlist)
predict(spec_list, yhat[10,])
predict(spec_list, yhat[10,])
predict(spec_list, yhat[8,])
predict(spec_list, yhat[10,])
predict(spec_list, yhat[8,])
yhat[10,]
yhat[8,]
predict(spec_list, yhat[3,])
predict(spec_list, yhat[15,])
xd      <- data.frame(pH=7.6, EC=500, Temp=16, NO3=1, PO4=0.1)
pred_df <- predict(spec_list, xd)
ggplot(pred_df, aes(x=reorder(V1, -V2, mean), weight=V2, fill=V2))+ylab("Posterior probability P(Taxa|Data)")+
geom_bar(col="black")+theme_classic()+scale_fill_gradient(low="grey100", high = "grey0", limits=c(0,1))+labs(fill="P(Taxa|Data)")+
theme(axis.text.x = element_text(angle = 45, hjust = 1),
axis.title.x = element_blank())
predict(spec_list, as.data.frame(yhat[3,]))
predict(spec_list, as.data.frame(yhat[15,]))
predict(spec_list, as.data.frame(yhat[3,]))
predict(spec_list, as.data.frame(yhat[15,]))
predict(spec_list, as.data.frame(yhat[3,]))
predict(spec_list, as.data.frame(yhat[15,]))
predlist <- list()
for(i in 1:nrow(yhat)){
predlist[[i]] <- predict(spec_list, as.data.frame(yhat[i,]))[,-1]}
what <- do.call(cbind, predlist)
View(what)
View(what)
what[2,]
cite("bezier")
x <- c(0.3, 0.32, 0.27, 0.23, 0.4)
mean(x)
x <- c(0.3, 0.32, 0.27, 0.23, 0.41)
mean(x)
library(readxl)
library(ggplot2)
library(R2jags)
library(tidyr)
library(devtools)
library(gridExtra)
library(grid)
library(bezier)
#For further information check https://snwikaij.github.io/EcoPostView/EcoPostView.html
#One needs to install the package from GitHub
#install.github("snwikaij/EcoPostView")
library(EcoPostView)
#Upload the literature
literature <- read_excel("C:/Users/admin/OneDrive/Bureaublad/Paper3/parameter_est4.xlsx")
#Upload the priors
priors     <- read_excel("C:/Users/admin/OneDrive/Bureaublad/Paper3/parameters.xlsx", sheet = 2)
#Total number of articles
nrow(litres2 <- literature[!duplicated(literature$DOI),])
#Systematic and non-systematic
table(literature$sys[!duplicated(literature$DOI)])
#Total number of models
nrow(litres1 <- literature[literature$Parameter == "b0",])
#Log and logit-linear models
table(literature$Link[literature$Parameter == "b0"])
#Total log and logit-linear models
table(literature$Link[literature$Parameter == "b1"])
#Create dataset for the model
mod_data <- data.frame(group=literature$Response,
predictor=literature$Fignames,
level=paste(literature$Parameter, literature$Type, literature$Link, literature$Response, sep = "_"),
estimate=literature$estimate,
stderr=literature$estimate_se,
linkfun=literature$Link)
#Full model
mod <- meta(estimate = mod_data$estimate,
stderr = mod_data$stderr,
parameter = do.call(rbind, strsplit(mod_data$level, "_"))[,1],
predictor = mod_data$predictor,
link_function = mod_data$linkfun,
grouping = mod_data$group,
prior_mu = as.data.frame(priors[c(2,4,6,8)]),
prior_mu_se = as.data.frame(priors[c(3,5,7,9)]),
n_iter = 15000,
n_thin = 30,
n_chain= 30)
mod$Summary
library(readxl)
library(ggplot2)
library(R2jags)
library(tidyr)
library(devtools)
library(gridExtra)
library(grid)
#For further information check https://snwikaij.github.io/EcoPostView/EcoPostView.html
#One needs to install the package from GitHub
#install.github("snwikaij/EcoPostView")
library(EcoPostView)
#Upload the literature
literature <- read_excel("C:/Users/admin/OneDrive/Bureaublad/Paper3/parameter_est4.xlsx")
#Upload the priors
priors     <- read_excel("C:/Users/admin/OneDrive/Bureaublad/Paper3/parameters.xlsx", sheet = 1)
library(readxl)
library(ggplot2)
library(R2jags)
library(tidyr)
library(devtools)
library(gridExtra)
library(grid)
#For further information check https://snwikaij.github.io/EcoPostView/EcoPostView.html
#One needs to install the package from GitHub
#install.github("snwikaij/EcoPostView")
library(EcoPostView)
#Upload the literature
literature <- read_excel("C:/Users/admin/OneDrive/Bureaublad/Paper3/parameter_est4.xlsx")
#Upload the priors
priors     <- read_excel("C:/Users/admin/OneDrive/Bureaublad/Paper3/parameters.xlsx", sheet = 1)
#Total number of articles
nrow(litres2 <- literature[!duplicated(literature$DOI),])
#Systematic and non-systematic
table(literature$sys[!duplicated(literature$DOI)])
#Total number of models
nrow(litres1 <- literature[literature$Parameter == "b0",])
#Log and logit-linear models
table(literature$Link[literature$Parameter == "b0"])
#Total log and logit-linear models
table(literature$Link[literature$Parameter == "b1"])
#Create dataset for the model
mod_data <- data.frame(group=literature$Response,
predictor=literature$Fignames,
level=paste(literature$Parameter, literature$Type, literature$Link, literature$Response, sep = "_"),
estimate=literature$estimate,
stderr=literature$estimate_se,
linkfun=literature$Link)
#Full model
mod <- meta(estimate = mod_data$estimate,
stderr = mod_data$stderr,
parameter = do.call(rbind, strsplit(mod_data$level, "_"))[,1],
predictor = mod_data$predictor,
link_function = mod_data$linkfun,
grouping = mod_data$group,
prior_mu = as.data.frame(priors[c(2,4,6,8)]),
prior_mu_se = as.data.frame(priors[c(3,5,7,9)]),
n_iter = 15000,
n_thin = 30,
n_chain= 30)
order_p     <- c("Salinity-increase", "Oxygen-depletion", "Sediment-enrichment", "Warming", "Flow-cessation", "N-increase", "P-increase")
order_g     <- c("Bacteria", "Algae", "Macrophytes", "Invertebrates", "Fish")
#I am (as main author) the least happy with this. To bring this to a general audience the
#relation of flow and oxygen was inversed. Hence, the idea is that flow increase and oxygen
#increase are not stressors. Therefore they are inversed by multiplying with -1.
#The issue I have is that there exists no inverse of flow velocity (m/s) and oxygen (mg/l).
#For proper interpretation and prediction it does not work well.
mod_inv <- mod
mod_inv$Estimates$b1$estimate[mod_inv$Estimates$b1$predictor %in% c("Flow-cessation", "Oxygen-depletion")] <- -1*mod_inv$Estimates$b1$estimate[mod_inv$Estimates$b1$predictor %in% c("Flow-cessation", "Oxygen-depletion")]
#Sensitivity check
mod_sens <- meta(estimate = mod_data$estimate,
stderr = mod_data$stderr,
parameter = do.call(rbind, strsplit(mod_data$level, "_"))[,1],
predictor = mod_data$predictor,
link_function = mod_data$linkfun,
grouping = mod_data$group,
prior_mu = 0,
prior_mu_se = 10,
n_iter = 15000,
n_thin = 30,
n_chain= 30)
postdens       <- pdplot(mod_inv, title_size = 2, point_size = .8, line_width = .7, err_bar_lwd = .5,
xlab=c("Pooled parameter estimate [=regression coefficient]"),
ylab=c("Probability distribution"),
order_predictor = order_p, order_group = order_g)
postdens       <- pdplot(mod_inv, title_size = 2, point_size = .8, line_width = .7, err_bar_lwd = .5,
xlab=c("Pooled parameter estimate [=regression coefficient]"),
ylab=c("Probability distribution"),
order_predictor = order_p, order_group = order_g)
title_pl_log   <- ggplot()+theme_void()+annotate("text", 0, 0, size = 6, label="Taxonomic richness")
title_pl_logit <- ggplot()+theme_void()+annotate("text", 0, 0, size = 6, label="Evenness")
pdp_combined <- cowplot::plot_grid(title_pl_log,
postdens$posterior_density$log,
title_pl_logit,
postdens$posterior_density$logit,
ncol=1,
rel_heights = c(0.025, 0.225, 0.025, 0.225))
ggsave(pdp_combined, filename="C:/Users/admin/OneDrive/Bureaublad/Paper3/Figures/Fig_2.jpeg", units = "mm", width = 190, height = 240, dpi = 300)
mod$Summary
writexl::write_xlsx(as.data.frame(mod$Summary), "results.xlsx")
#Upload the literature
url         <- "https://github.com/snwikaij/Data/blob/main/Unknown_Kaijser_et_al._Data_and_priors.xlsx"
destfile    <- tempfile(fileext = ".xlsx")
download.file(url, destfile, mode = "wb")
literature  <- read_xlsx(destfile, "Data")
#Upload the data (literature) and priors
url         <- "https://github.com/snwikaij/Data/blob/main/Unknown_Kaijser_et_al._Data_and_priors.xlsx"
destfile    <- tempfile(fileext = ".xlsx")
download.file(url, destfile, mode = "wb")
literature  <- read_xlsx(destfile, "Data")
literature  <- read_xlsx(destfile, 1)
library(readxl)
library(ggplot2)
library(R2jags)
library(tidyr)
library(devtools)
library(gridExtra)
library(grid)
#For further information check https://snwikaij.github.io/EcoPostView/EcoPostView.html
#One needs to install the package from GitHub
#install.github("snwikaij/EcoPostView")
library(EcoPostView)
#Upload the data (literature) and priors
url         <- "https://github.com/snwikaij/Data/blob/main/Unknown_Kaijser_et_al._Data_and_priors.xlsx"
destfile    <- tempfile(fileext = ".xlsx")
download.file(url, destfile, mode = "wb")
literature  <- read_xlsx(destfile, 1)
literature  <- read_xlsx(destfile, 2)
#Upload the data (literature) and priors
url         <- "https://github.com/snwikaij/Data/blob/main/Unknown_Kaijser_et_al._Data_and_priors.xlsx"
destfile    <- tempfile(fileext = ".xlsx")
download.file(url, destfile, mode = "wb")
literature  <- read_xlsx(destfile, 2)
#Upload the data (literature) and priors
url         <- "https://github.com/snwikaij/Data/blob/main/Unknown_Kaijser_et_al._Data_and_priors.xlsx"
destfile    <- tempfile(fileext = ".xlsx")
literature  <- read_xlsx(destfile, 2)
#Upload the data (literature) and priors
url         <- "https://github.com/snwikaij/Data/blob/main/Unknown_Kaijser_et_al._Data_and_priors.xlsx"
destfile    <- tempfile(fileext = ".xlsx")
download.file(url, destfile, mode = "wb")
literature  <- read_xlsx(destfile, 2)
literature  <- read_xlsx(destfile, 1)
#Upload the data (literature) and priors
url         <- "https://raw.githubusercontent.com/snwikaij/Data/main/Unknown_Kaijser_et_al._Data_and_priors.xlsx"
destfile    <- tempfile(fileext = ".xlsx")
download.file(url, destfile, mode = "wb")
literature  <- read_xlsx(destfile, 2)
View(literature)
literature  <- read_xlsx(destfile, 1)
priors      <- read_xlsx(destfile, 3)
#Total number of articles
nrow(litres2 <- literature[!duplicated(literature$DOI),])
#Systematic and non-systematic
table(literature$sys[!duplicated(literature$DOI)])
#Total number of models
nrow(litres1 <- literature[literature$Parameter == "b0",])
#Log and logit-linear models
table(literature$Link[literature$Parameter == "b0"])
#Total log and logit-linear models
table(literature$Link[literature$Parameter == "b1"])
#Create dataset for the model
mod_data <- data.frame(group=literature$Response,
predictor=literature$Fignames,
level=paste(literature$Parameter, literature$Type, literature$Link, literature$Response, sep = "_"),
estimate=literature$estimate,
stderr=literature$estimate_se,
linkfun=literature$Link)
#Full model
mod <- meta(estimate = mod_data$estimate,
stderr = mod_data$stderr,
parameter = do.call(rbind, strsplit(mod_data$level, "_"))[,1],
predictor = mod_data$predictor,
link_function = mod_data$linkfun,
grouping = mod_data$group,
prior_mu = as.data.frame(priors[c(2,4,6,8)]),
prior_mu_se = as.data.frame(priors[c(3,5,7,9)]),
n_iter = 15000,
n_thin = 30,
n_chain= 30)
#Detect OS to set wd
os <- Sys.info()["sysname"]
user <- Sys.info()["user"]
if (os == "Windows") {
setwd(paste0("C:/Users/", user, "/Desktop/Figures"))
} else if (os == "Linux" || os == "Darwin") {  # Darwin is macOS
setwd(paste0("/home/", user, "/Desktop/Figures"))
} else {
stop("Unsupported operating system")
}
# Check if the working directory is set correctly
print(getwd())
