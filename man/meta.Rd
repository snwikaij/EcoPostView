% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/meta.R
\name{meta}
\alias{meta}
\title{Bayesian Meta-Analysis}
\usage{
meta(
  estimate,
  stderr,
  parameter = NULL,
  predictor = NULL,
  link_function = NULL,
  grouping = NULL,
  random = NULL,
  moderator = NULL,
  method = 0,
  Nsamp = NULL,
  prior_mu = 0,
  prior_mu_se = 10,
  prior_study_var = NULL,
  prior_fam_var = "unif1",
  fixed_prior = FALSE,
  interval = 0.9,
  get_prior_only = FALSE,
  n_chain = 2,
  n_thin = 1,
  n_seed = 666,
  n_iter = 10000,
  n_burnin = 1000,
  Rhat_warn = 1.01,
  Eff_warn = 1000,
  print_summary = FALSE
)
}
\arguments{
\item{estimate}{Parameter b0 or b1 estimated from a LM or GLM}

\item{stderr}{Standard error belonging to b0 and b1}

\item{parameter}{A category (name) either b0 or b1}

\item{predictor}{A predictor name (e.g., salinity) as multiple predictors can be handled}

\item{link_function}{The link function of the LM or GLM currently only 'identity', 'logit' and 'log' are supported and will only be used in the hop function}

\item{grouping}{A category (name) for the group as multiple groups can be handled}

\item{random}{An argument that needs to be a vector or  matrix of factors of the same number of rows as the estimate}

\item{method}{Indicates which adjustment performed 0 (='none'), 1 (='egger') or 2 (='peters')}

\item{Nsamp}{A vector with the number of samples for each estimate (only used when method = 2)}

\item{prior_mu}{Prior for the mean which can be vector (Bayesian meta-analysis) or matrix (Bayesian meta-analysis with model averaging)}

\item{prior_mu_se}{Prior for the se which can be vector or matrix}

\item{prior_study_var}{Prior for the between study variance if RE=T. If the argument prior_fam_var indicates the family is 'unif1' or 'unif2', then a uniform prior is used between 0 and the maximum value indicated by prior_study_var (default=abs(max(estimate-mean(estimate)))*2) meaning Uniform(0, prior_study_var).
If prior_fam_var is 'exp' the the rate indicated bye prior_study_var. This is by default 0.001 meaning Exponential(prior_study_var).}

\item{prior_fam_var}{The distribution family used for the prior of the between study variance. Uniform1 = 'unif1' this uses the uniform distribution as a 'scaling parameter over all studies'. This can be beneficial is one does not want to make
assumptions about the between study variance and a large number of levels is present with sometimes small sample sizes. The between study variance is then estimated as the overall between study variance, but not for each level individual.
Uniform2 = 'unif2' estimates the between study variance for each individual level. This is useful when one no assumptions wants to make over the between study variance and a large number of studies is present for each level.
The Exponential = 'exp' estimates the between study variance for each individual level based on the exponential distribution (default='unif1').This is beneficial if only a small number of levels and samples are present. With unif1 or unif2 the intervals can become
very broad with might be beneficial if one wants to be conservative. However, it can be a disadvantage because that the variability of the parameter gets overly broad (default = 'unif1')}

\item{fixed_prior}{by default the prior weights are treated as stochastically generated from a Dirichlet distribution (fixed_prior=FALSE). It is possible to treat them as fixed (fixed_prior=TRUE). Under fixed conditions all priors are appointed equal prior weights as 1/number of priors.}

\item{interval}{Credibility intervals for the summary (default=0.9)}

\item{get_prior_only}{If it is unclear how many levels and how to formulate multiple priors for each level this argument will only return a data frame of priors so that formulating priors for levels is easier}

\item{n_chain}{Number of chains}

\item{n_thin}{Thinning interval of the chains}

\item{n_seed}{Seed}

\item{n_iter}{Number of iterations}

\item{n_burnin}{Burn-in period}

\item{Rhat_warn}{Warning level for Rhat}

\item{Eff_warn}{Warning level for Effective sample size}

\item{print_summary}{If TRUE it prints a summary}
}
\description{
Full Bayesian Random-Effect meta-analytic method with the possiblity of using Bayesian Model Averaging. It additionally has the possibility - internally - to adjust
for publication bias with Egger adjustment using the standard error (\emph{SE^2}; Moreno et al., 2009; Stanley  and Doucouliagos, 2013) or Peters adjustment (Moreno et al., 2009) using
the inverse of the sample size (N). The full use of the meta function is the combination with pdplot and hop function. Hence it  is used to analyse
the parameter estimates intercepts (b0) and regression coefficients (b1) on of LM or GLM models applied when the independent
variable is continues.

This package was first develop to analyse the  parameters when the independent variable (predictor variable) was log (natural log)
transformed and either the link functions are 'log' or 'logit' are used, or the dependent variable (target or response variable) is log transformed and
'identity' link is used. Under such conditions the estimate parameter is named the (semi-)elasticity coefficient. The
elasticity coefficient indicates the percentage change in the target variable per 1 percent increase in the predictor variable.
The advantage is that the units of the regression coefficient (b1) are retained: g(E(y|x))=b0+b1\emph{log(x)+error. If the link function (g) is a
log-link the log(E(y|x))=b0+b1}log(x) and so b1=log(E(y|x))/log(x) the units for x (e.g.,TP mg/L) and y (e.g., species richness) are retained.
And b1 still has its interpretation on the log-scale (log(species richness)/log(TP mg/L)). Therefore if b1=-0.2 this indicates
a 0.2\% decline in species richness per increase in 1\% TP. Furthermore, the decline in species richness can still be predicted
as a function of the increase in log(x) because 'species  richness' = exp(b1*log(x)). This also makes broad comparisons
between different 'groupings' possible due to the scaling of the parameters.

This does not mean that other estimated parameters cannot be analysed. However, I specifically designed this for comparisons
(e.g., using density plots in the pdplot function) among such parameters or to generate  and finally to generate HOP-lines
using the (hop function). This can all be performed without losing the interpretation of the parameter which then tells us something
ecological senseful about the relation between predictor and target variable. This 'sense' is lost when looking at correlation coefficients, or standardized
effect sizes (Tukey 1969; Baguley 2009; Correl et al., 2020). Hence, what does Cohens' D tell us about the impact of oxygen depletion on EPT-taxa
When it is found to be 1: The mean difference between two groups divided by its pooled standard deviation. And how do we judge this to
be ecologically 'relevant'. Relatively little, considering there is a gradual relation between O2 and the number of EPT-taxa, which is only
retained within the units of the parameter e.g., -0.2 EPT-taxa/log(O2 mg/L). Additionally is our data so noisy that any deviation is
expected due to the noise alone. More importantly we cannot either asses our long-run estimations or used them in our prior or compare
our posterior. Thus transforming to standardized-effect sizes is an incredible waste of information if the underlying data not is
provided.
}
\note{
Which prior variance 'family' needs to be selected on the between study variance is still unclear to me.
I am not sure if there is an approximate optimal answer but would like to have one. It is possible to get unreasonable answers
due to the extremely large or small variance among studies and variability in sample sizes when using 'unif2' or 'exp'.
However extremely wide intervals across all levels are also possible when using 'unif1'. This means then that smaller pattern will not
come out very clear.

The 'unif1' could prevents over fitting to small-group variances for smaller sample sizes. Therefore it a conservative
but stable approximate answer seems preferable at first glance. Consequently repetition could be performed in an second study
with a less conservative hierarchical structure where 'unif2' and 'exp' could be utilized.

If Nsamp (NA) this is replaced by 1 since 1/N where N=1 is 1=1/1.
}
\examples{
data("example1")

#Standard random effect (RE) meta-analysis
mod <-meta(estimate=example1$est, stderr=example1$se,
          parameter=example1$parameter, predictor=example1$predictor,
          link_function=example1$link, grouping=example1$group)

#Standard random effect (RE) meta-analysis with egger's correction
mod <-meta(estimate=example1$est, stderr=example1$se,
          parameter=example1$parameter, predictor=example1$predictor,
          link_function=example1$link, grouping=example1$group, method=1)

#Standard random effect (RE) meta-analysis with peter's correction
mod <-meta(estimate=example1$est, stderr=example1$se,
          parameter=example1$parameter, predictor=example1$predictor,
          link_function=example1$link, grouping=example1$group,
          Nsamp=example1$n, method=2)

}
